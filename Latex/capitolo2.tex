\chapter{Acquisizione dei dati}
Come già accennato, l'addestramento delle reti neurali convoluzionali richiede un dataset. Il training set deve essere sufficientemente grande in modo che la rete possa generalizzare in modo appropriato, cioè dare risultati plausibili per input che non ha mai visto. Al momento, tuttavia, l'acquisizione accurata di dati ground truth per scene 3D reali non è una operazione immediata. Per questa ragione, in questo lavoro verrà utilizzato un dataset sintetico simulato con \textit{Blender} composto da 55 scene 3D differenti. Le scene contengono diverse problematiche di acquisizione che includono riflessi, diversi tipi di illuminazione, e pattern ripetitivi. 

\section{Preparazione dei dati}
Per poter compiere una corretta fusione delle informazioni tridimensionali del ToF camera e del sensore stereo, bisogna fare in modo che i dati forniti siano all'interno dello stesso sistema di riferimento.

\paragraph{Interpolazione e riproiezione}
Il sensore Time-of-Flight fornisce una mappa di profondità della scena. Per poter eseguire la fusione con i dati restituiti dal sensore stereo, bisogna tenere conto le diverse risoluzioni. Infatti, il sensore ToF ha una risoluzione nettamente inferiore rispetto alle moderne telecamere a colori, perciò è necessario interpolare le immagini restituite in modo da portarlo alla risoluzione delle telecamere stereo.\\
Inoltre, le informazioni sulla profondità del sensore ToF vengono riproiettate sulla prospettiva della telecamera a colori di riferimento che, senza perdita di generalità, assumiamo essere la telecamera destra della coppia stereo. 

\paragraph{Calcolo della disparità}
Il sensore Time-of-Flight e il sensore stereo rappresentano la scena 3D in modo differente. Come già visto, il sistema stereo ritorna una mappa di disparità dove ogni pixel rappresenta la differenza di posizione tra i punti omologhi nelle due immagini. La ToF camera d'altro canto ritorna una mappa di profondità nella quale ogni pixel esprime la distanza tra il sensore e il corrispondente punto sulla scena. La disparità e la profondità sono legate da una relazione di proporzionalità inversa:
$$z=\frac{b\cdot f}{d}$$
dove $z$ è la distanza, $d$ è la disparità, $b$ è la baseline dello stereo e $f$ è la lunghezza focale delle telecamere \cite{rif1}. La disparità è stata scelta come unità di misura comune, dunque la mappa di profondità del ToF viene convertita in una mappa di disparità in modo tale da rendere omogenee le rappresentazioni dei due sensori.

\paragraph{Data augmentation}
Per \textit{data augmentation} si intende una tecnica che consiste nell'apportare alcune modifiche casuali nelle istanze del dataset, come rotazioni, ritagli, traslazioni e altre operazioni di image processing. Lo scopo è quello di ampliare il numero di esempi nel training set per una maggiore robustezza e variabilità, e di conseguenza ridurre le probabilità di overfitting.\\
Per questo lavoro sono stati effettuati casualmente operazioni di ritaglio, ribaltazione orizzontale e verticale dell'immagine e rotazione di $\pm \ang{5}$. Il prodotto di queste operazioni è un training set composto da 3902 esempi di dimensioni 128x128.