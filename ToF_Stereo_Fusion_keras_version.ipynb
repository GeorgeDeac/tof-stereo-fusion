{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToF Stereo Fusion - keras version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOgMTP7i3hkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Activation, BatchNormalization, Conv2D, Concatenate\n",
        "from keras.models import Model, load_model\n",
        "from datetime import datetime\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import tables\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/My Drive/Tesi/Colab working dir'\n",
        "\n",
        "# from keras.backend.tensorflow_backend import set_session\n",
        "# import tensorflow as tf\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
        "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
        "# sess = tf.Session(config=config)\n",
        "# set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
        "\n",
        "# K.set_image_data_format('channels_last')\n",
        "# K.set_learning_phase(1)\n",
        "\n",
        "#!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "#from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAvb3WNB5tEQ",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./keras_logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktw20PRTygLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_num = 50\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "early_stopping_patience = 10\n",
        "n_blocks = 6\n",
        "filepath = 'dataset_without_amplitude.mat'\n",
        "n_channels = 2\n",
        "#checkpoints_dir = \"keras_logs/noamp/version_4/{}blocks_7x7first_1downconv_add/\".format(n_blocks)\n",
        "#checkpoints_dir = \"keras_logs/noamp/version_3_1downconvadd/{}blocks_{}-{}-{}_7x7first_1downconv_add/\".format(n_blocks, filters[0], filters[1], filters[2])\n",
        "current_time = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "checkpoints_dir = \"keras_logs/noamp/{}/\".format(current_time)\n",
        "\n",
        "print(\"loading dataset\")\n",
        "mat_content = tables.open_file(filepath)\n",
        "\n",
        "training_data = mat_content.root.training_data[:]\n",
        "training_label = mat_content.root.training_label[:]\n",
        "validation_full_data = mat_content.root.validation_full_data[:]\n",
        "validation_full_label = mat_content.root.validation_full_label[:]\n",
        "test_data = mat_content.root.test_data[:]\n",
        "test_label = mat_content.root.test_label[:]\n",
        "\n",
        "\n",
        "print(\"training samples: {}\".format(len(training_data)))\n",
        "print(\"validation samples: {}\".format(len(validation_full_data)))\n",
        "print(\"test samples: {}\".format(len(test_data)))\n",
        "\n",
        "print(training_data.shape)\n",
        "print(training_label.shape)\n",
        "print(validation_full_data.shape)\n",
        "print(validation_full_label.shape)\n",
        "print(test_data.shape)\n",
        "print(test_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COCAjk8zzCHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(X, name):\n",
        "    return BatchNormalization(axis = -1, name = name)(X)\n",
        "    #return InstanceNormalization(name = name)(X)\n",
        "\n",
        "def simple_block(X, f, filters, block, dilation=1):\n",
        "    conv_name_base = 'res' + str(block)\n",
        "    bn_name_base = 'norm' + str(block)\n",
        "    \n",
        "    X = Conv2D(filters = filters, kernel_size = (f, f), strides = (1, 1), padding = 'same', dilation_rate=dilation, name = conv_name_base)(X)\n",
        "    X = norm(X, name = bn_name_base + 'b')\n",
        "    X = Activation('relu')(X)\n",
        "    return X\n",
        "\n",
        "def identity_block(X, f, filters, block, dilation=1):\n",
        "    \n",
        "    # Defining name basis\n",
        "    conv_name_base = 'res' + str(block)\n",
        "    bn_name_base = 'norm' + str(block)\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + 'a')(X)\n",
        "    X = norm(X, name = bn_name_base + 'a')\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', dilation_rate=dilation, name = conv_name_base + 'b')(X)\n",
        "    X = norm(X, name = bn_name_base + 'b')\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + 'c')(X)\n",
        "    X = norm(X, name = bn_name_base + 'c')\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "def convolutional_block(X, f, filters, block, dilation=1):\n",
        "\n",
        "    # Defining name basis\n",
        "    conv_name_base = 'res' + str(block)\n",
        "    bn_name_base = 'norm' + str(block)\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + 'a')(X)\n",
        "    X = norm(X, name = bn_name_base + 'a')\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', dilation_rate=dilation, name=conv_name_base + 'b')(X)\n",
        "    X = norm(X, name = bn_name_base + 'b')\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + 'c')(X)\n",
        "    X = norm(X, name = bn_name_base + 'c')\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + 's')(X_shortcut)\n",
        "    X_shortcut = norm(X_shortcut, name=bn_name_base + 's')\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def res_block(X, filters, block, dilation=1):\n",
        "    conv_name_base = 'res' + str(block)\n",
        "    bn_name_base = 'norm' + str(block)\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component\n",
        "    X = Conv2D(filters = filters, kernel_size = (3, 3), strides = (1,1), padding = 'same', dilation_rate=dilation, name = conv_name_base + 'a')(X)\n",
        "    X = norm(X, name = bn_name_base + 'a')\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = filters, kernel_size = (3, 3), strides = (1,1), padding = 'same', dilation_rate=dilation, name = conv_name_base + 'b')(X)\n",
        "    X = norm(X, name = bn_name_base + 'b')\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "def resnet_bottleneck(X):\n",
        "    kernel_size = 3\n",
        "    filters = [32, 32, 128]\n",
        "    X = convolutional_block(X, 7, filters, block=0)\n",
        "    for i in range (1, n_blocks):\n",
        "        X = identity_block(X, kernel_size, filters, block=i, dilation=2)\n",
        "    return X\n",
        "    \n",
        "def resnet(X):\n",
        "    filters = 32\n",
        "    X = Conv2D(filters = filters, kernel_size = (7,7), strides = (1,1), padding = 'same', name = 'start_conv')(X)\n",
        "    for i in range (1, n_blocks):\n",
        "        X = res_block(X, filters, block=i)\n",
        "    return X\n",
        "\n",
        "def simple_net(X):\n",
        "    filters = 32\n",
        "    X = simple_block(X, 7, filters, 0)\n",
        "    for i in range (1, n_blocks):\n",
        "        X = simple_block(X, 3, filters, i, dilation=2)\n",
        "    return X\n",
        "\n",
        "def generate_model(n_channels):\n",
        "    input_shape = (None,None,n_channels)\n",
        "    \n",
        "    X_input = Input(shape = input_shape)\n",
        "    \n",
        "    X = resnet_bottleneck(X_input)\n",
        "    X = Conv2D(filters = 2, kernel_size = (1, 1), strides = (1,1), padding = 'same', name = 'down_conv')(X)\n",
        "    \n",
        "    X = Concatenate()([X, X_input])\n",
        "    X = Activation('relu')(X)\n",
        "    X = Conv2D(filters = 1, kernel_size = (1, 1), strides = (1,1), padding = 'same', name = 'final_conv')(X)\n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X, name='MyModel')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = generate_model(n_channels)\n",
        "#model.summary()\n",
        "plot_model(model, to_file='model_scheme.png', show_shapes=True, rankdir='TB')\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFzXcly6EmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience)\n",
        "tensorboard = TensorBoard(log_dir=checkpoints_dir)\n",
        "\n",
        "model.fit(training_data, \n",
        "          training_label, \n",
        "          epochs = epoch_num, \n",
        "          batch_size = batch_size, \n",
        "          validation_data=(validation_full_data, validation_full_label),\n",
        "          callbacks=[tensorboard, early_stopping])\n",
        "\n",
        "model.save(checkpoints_dir+\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhcdbGlM4Z0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = load_model('keras_logs/noamp/version_2_concat/6blocks_32-32-128_dilated_7x7first_withrelu/model.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6ATFAI-leu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('keras_logs/noamp/version_2_concat/6blocks_32-32-128_dilated_7x7first_withrelu/model.h5')\n",
        "plot_model(model, to_file='model_scheme_1.png', show_shapes=True, rankdir='TB')\n",
        "val_or_test = False #True for validation, False for test\n",
        "data_input = validation_full_data if val_or_test else test_data\n",
        "data_label = validation_full_label if val_or_test else test_label\n",
        "batch_size = 4 if val_or_test else 5\n",
        "\n",
        "mse = model.evaluate(data_input, data_label, batch_size=batch_size)\n",
        "print(\"mean squared error: \"+str(mse))\n",
        "\n",
        "outputs = model.predict(data_input, batch_size=batch_size)\n",
        "\n",
        "def showImagesHorizontally(images):\n",
        "    fig = plt.figure(figsize=(20, 20))\n",
        "    number_of_images = len(images)\n",
        "    for i in range(number_of_images):\n",
        "        a=fig.add_subplot(1,number_of_images,i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "def showImagesConcatenated(images):\n",
        "    image = np.concatenate(images, axis=1)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(image)\n",
        "        \n",
        "for i in range(len(outputs)):\n",
        "    images = []\n",
        "    fused = np.squeeze(outputs[i])\n",
        "    label = np.squeeze(data_label[i])\n",
        "    tof = np.squeeze(data_input[i,:,:,1])\n",
        "    stereo = np.squeeze(data_input[i,:,:,0])\n",
        "    #images.append(np.squeeze(input_images[batch][i,:,:,3])) #stereodiff\n",
        "    images.append(tof)\n",
        "    images.append(stereo)\n",
        "    images.append(fused)\n",
        "    images.append(label)\n",
        "    images.append(np.abs(fused-label)) #difference\n",
        "\n",
        "    showImagesHorizontally(images)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAT8PDtKYMsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = load_model('keras_logs/noamp/6blocks_32-32-128_dilated_7x7first/model.h5')\n",
        "input_layer = model.input\n",
        "layer_out = model.get_layer(\"activation_75\").output\n",
        "model_middle = Model(input=input_layer, outputs=layer_out)\n",
        "data = validation_full_data[0:4]\n",
        "outputs = model_middle.predict(data, batch_size=4)\n",
        "print(np.shape(outputs))\n",
        "\n",
        "for sample in range(len(outputs)):\n",
        "    images = []\n",
        "    for i in range(0,4):\n",
        "        images.append(outputs[sample,:,:,i])\n",
        "    showImagesHorizontally(images)\n",
        "    #image = np.concatenate(images, axis=1)\n",
        "    #plt.figure(figsize=(20, 20))\n",
        "    #plt.imshow(image, vmin=0, vmax=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}